{
  "adapter_spec": {
    "method": "multiple_choice_joint_multimodal",
    "global_prefix": "",
    "global_suffix": "",
    "instructions": "Answer the multiple choice question by just giving the letter of the correct answer.",
    "input_prefix": "",
    "input_suffix": "\n",
    "reference_prefix": "A. ",
    "reference_suffix": "\n",
    "chain_of_thought_prefix": "",
    "chain_of_thought_suffix": "\n",
    "output_prefix": "Answer: ",
    "output_suffix": "\n",
    "instance_prefix": "\n",
    "substitutions": [],
    "max_train_instances": 0,
    "max_eval_instances": 10,
    "num_outputs": 1,
    "num_train_trials": 1,
    "num_trials": 1,
    "sample_train": true,
    "model_deployment": "huggingface/qwen2.5-vl-3b-instruct-ft-50",
    "model": "custom/qwen2.5-vl-3b-instruct-ft-50",
    "temperature": 0.0,
    "max_tokens": 1,
    "stop_sequences": [
      "\n"
    ],
    "multi_label": false
  },
  "request_states": [
    {
      "instance": {
        "input": {
          "text": "",
          "multimedia_content": {
            "media_objects": [
              {
                "content_type": "image/jpeg",
                "location": "benchmark_output/scenarios/a_okvqa/images/DPtUMrxDbLP2nQ9yUdmvkT.jpg"
              },
              {
                "content_type": "text/plain",
                "text": "How many vehicles have their lights on?"
              }
            ]
          }
        },
        "references": [
          {
            "output": {
              "text": "three"
            },
            "tags": []
          },
          {
            "output": {
              "text": "one"
            },
            "tags": []
          },
          {
            "output": {
              "text": "none"
            },
            "tags": []
          },
          {
            "output": {
              "text": "two"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "valid",
        "id": "id17323"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "A": "three",
        "B": "one",
        "C": "none",
        "D": "two"
      },
      "request": {
        "model_deployment": "huggingface/qwen2.5-vl-3b-instruct-ft-50",
        "model": "custom/qwen2.5-vl-3b-instruct-ft-50",
        "embedding": false,
        "prompt": "",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 1,
        "stop_sequences": [],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0,
        "multimodal_prompt": {
          "media_objects": [
            {
              "content_type": "text/plain",
              "text": "Answer the multiple choice question by just giving the letter of the correct answer."
            },
            {
              "content_type": "text/plain",
              "text": "\n"
            },
            {
              "content_type": "image/jpeg",
              "location": "benchmark_output/scenarios/a_okvqa/images/DPtUMrxDbLP2nQ9yUdmvkT.jpg"
            },
            {
              "content_type": "text/plain",
              "text": "How many vehicles have their lights on?\nA. three\nB. one\nC. none\nD. two\nAnswer:"
            }
          ]
        }
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "D",
            "logprob": 0,
            "tokens": [
              {
                "text": "D",
                "logprob": 0
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.7568180561065674,
        "request_datetime": 1764552232
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "",
          "multimedia_content": {
            "media_objects": [
              {
                "content_type": "image/jpeg",
                "location": "benchmark_output/scenarios/a_okvqa/images/XkEu3gmYW23qTivgmHP3fN.jpg"
              },
              {
                "content_type": "text/plain",
                "text": "What does the color of the stoplight mean?"
              }
            ]
          }
        },
        "references": [
          {
            "output": {
              "text": "go"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "stop"
            },
            "tags": []
          },
          {
            "output": {
              "text": "get out"
            },
            "tags": []
          },
          {
            "output": {
              "text": "caution"
            },
            "tags": []
          }
        ],
        "split": "valid",
        "id": "id17756"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "A": "go",
        "B": "stop",
        "C": "get out",
        "D": "caution"
      },
      "request": {
        "model_deployment": "huggingface/qwen2.5-vl-3b-instruct-ft-50",
        "model": "custom/qwen2.5-vl-3b-instruct-ft-50",
        "embedding": false,
        "prompt": "",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 1,
        "stop_sequences": [],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0,
        "multimodal_prompt": {
          "media_objects": [
            {
              "content_type": "text/plain",
              "text": "Answer the multiple choice question by just giving the letter of the correct answer."
            },
            {
              "content_type": "text/plain",
              "text": "\n"
            },
            {
              "content_type": "image/jpeg",
              "location": "benchmark_output/scenarios/a_okvqa/images/XkEu3gmYW23qTivgmHP3fN.jpg"
            },
            {
              "content_type": "text/plain",
              "text": "What does the color of the stoplight mean?\nA. go\nB. stop\nC. get out\nD. caution\nAnswer:"
            }
          ]
        }
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "A",
            "logprob": 0,
            "tokens": [
              {
                "text": "A",
                "logprob": 0
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.8935332298278809,
        "request_datetime": 1764552232
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "",
          "multimedia_content": {
            "media_objects": [
              {
                "content_type": "image/jpeg",
                "location": "benchmark_output/scenarios/a_okvqa/images/XkEu3gmYW23qTivgmHP3fN.jpg"
              },
              {
                "content_type": "text/plain",
                "text": "What does da color of da stoplight mean?"
              }
            ]
          }
        },
        "references": [
          {
            "output": {
              "text": "go"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "stop"
            },
            "tags": []
          },
          {
            "output": {
              "text": "get out"
            },
            "tags": []
          },
          {
            "output": {
              "text": "caution"
            },
            "tags": []
          }
        ],
        "split": "valid",
        "id": "id17756",
        "perturbation": {
          "name": "dialect",
          "robustness": false,
          "fairness": true,
          "computed_on": "perturbed",
          "prob": 1.0,
          "source_class": "SAE",
          "target_class": "AAVE",
          "mapping_file_path": "benchmark_output/perturbations/dialect/SAE_to_AAVE_mapping.json"
        },
        "contrast_inputs": [
          {
            "text": "",
            "multimedia_content": {
              "media_objects": [
                {
                  "content_type": "image/jpeg",
                  "location": "benchmark_output/scenarios/a_okvqa/images/XkEu3gmYW23qTivgmHP3fN.jpg"
                },
                {
                  "content_type": "text/plain",
                  "text": "What does the color of the stoplight mean?"
                }
              ]
            }
          }
        ]
      },
      "train_trial_index": 0,
      "output_mapping": {
        "A": "go",
        "B": "stop",
        "C": "get out",
        "D": "caution"
      },
      "request": {
        "model_deployment": "huggingface/qwen2.5-vl-3b-instruct-ft-50",
        "model": "custom/qwen2.5-vl-3b-instruct-ft-50",
        "embedding": false,
        "prompt": "",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 1,
        "stop_sequences": [],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0,
        "multimodal_prompt": {
          "media_objects": [
            {
              "content_type": "text/plain",
              "text": "Answer the multiple choice question by just giving the letter of the correct answer."
            },
            {
              "content_type": "text/plain",
              "text": "\n"
            },
            {
              "content_type": "image/jpeg",
              "location": "benchmark_output/scenarios/a_okvqa/images/XkEu3gmYW23qTivgmHP3fN.jpg"
            },
            {
              "content_type": "text/plain",
              "text": "What does da color of da stoplight mean?\nA. go\nB. stop\nC. get out\nD. caution\nAnswer:"
            }
          ]
        }
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "A",
            "logprob": 0,
            "tokens": [
              {
                "text": "A",
                "logprob": 0
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.8930368423461914,
        "request_datetime": 1764552232
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "",
          "multimedia_content": {
            "media_objects": [
              {
                "content_type": "image/jpeg",
                "location": "benchmark_output/scenarios/a_okvqa/images/UYqcgLGSbQXzeDLUj6rZej.jpg"
              },
              {
                "content_type": "text/plain",
                "text": "What is the large white object on the elephant called?"
              }
            ]
          }
        },
        "references": [
          {
            "output": {
              "text": "tusk"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "tooth"
            },
            "tags": []
          },
          {
            "output": {
              "text": "horn"
            },
            "tags": []
          },
          {
            "output": {
              "text": "bone"
            },
            "tags": []
          }
        ],
        "split": "valid",
        "id": "id17678"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "A": "tusk",
        "B": "tooth",
        "C": "horn",
        "D": "bone"
      },
      "request": {
        "model_deployment": "huggingface/qwen2.5-vl-3b-instruct-ft-50",
        "model": "custom/qwen2.5-vl-3b-instruct-ft-50",
        "embedding": false,
        "prompt": "",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 1,
        "stop_sequences": [],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0,
        "multimodal_prompt": {
          "media_objects": [
            {
              "content_type": "text/plain",
              "text": "Answer the multiple choice question by just giving the letter of the correct answer."
            },
            {
              "content_type": "text/plain",
              "text": "\n"
            },
            {
              "content_type": "image/jpeg",
              "location": "benchmark_output/scenarios/a_okvqa/images/UYqcgLGSbQXzeDLUj6rZej.jpg"
            },
            {
              "content_type": "text/plain",
              "text": "What is the large white object on the elephant called?\nA. tusk\nB. tooth\nC. horn\nD. bone\nAnswer:"
            }
          ]
        }
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "A",
            "logprob": 0,
            "tokens": [
              {
                "text": "A",
                "logprob": 0
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.7559192180633545,
        "request_datetime": 1764552232
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "",
          "multimedia_content": {
            "media_objects": [
              {
                "content_type": "image/jpeg",
                "location": "benchmark_output/scenarios/a_okvqa/images/UYqcgLGSbQXzeDLUj6rZej.jpg"
              },
              {
                "content_type": "text/plain",
                "text": "What is da large white object on da elephant called?"
              }
            ]
          }
        },
        "references": [
          {
            "output": {
              "text": "tusk"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "tooth"
            },
            "tags": []
          },
          {
            "output": {
              "text": "horn"
            },
            "tags": []
          },
          {
            "output": {
              "text": "bone"
            },
            "tags": []
          }
        ],
        "split": "valid",
        "id": "id17678",
        "perturbation": {
          "name": "dialect",
          "robustness": false,
          "fairness": true,
          "computed_on": "perturbed",
          "prob": 1.0,
          "source_class": "SAE",
          "target_class": "AAVE",
          "mapping_file_path": "benchmark_output/perturbations/dialect/SAE_to_AAVE_mapping.json"
        },
        "contrast_inputs": [
          {
            "text": "",
            "multimedia_content": {
              "media_objects": [
                {
                  "content_type": "image/jpeg",
                  "location": "benchmark_output/scenarios/a_okvqa/images/UYqcgLGSbQXzeDLUj6rZej.jpg"
                },
                {
                  "content_type": "text/plain",
                  "text": "What is the large white object on the elephant called?"
                }
              ]
            }
          }
        ]
      },
      "train_trial_index": 0,
      "output_mapping": {
        "A": "tusk",
        "B": "tooth",
        "C": "horn",
        "D": "bone"
      },
      "request": {
        "model_deployment": "huggingface/qwen2.5-vl-3b-instruct-ft-50",
        "model": "custom/qwen2.5-vl-3b-instruct-ft-50",
        "embedding": false,
        "prompt": "",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 1,
        "stop_sequences": [],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0,
        "multimodal_prompt": {
          "media_objects": [
            {
              "content_type": "text/plain",
              "text": "Answer the multiple choice question by just giving the letter of the correct answer."
            },
            {
              "content_type": "text/plain",
              "text": "\n"
            },
            {
              "content_type": "image/jpeg",
              "location": "benchmark_output/scenarios/a_okvqa/images/UYqcgLGSbQXzeDLUj6rZej.jpg"
            },
            {
              "content_type": "text/plain",
              "text": "What is da large white object on da elephant called?\nA. tusk\nB. tooth\nC. horn\nD. bone\nAnswer:"
            }
          ]
        }
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "A",
            "logprob": 0,
            "tokens": [
              {
                "text": "A",
                "logprob": 0
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.83449387550354,
        "request_datetime": 1764552233
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "",
          "multimedia_content": {
            "media_objects": [
              {
                "content_type": "image/jpeg",
                "location": "benchmark_output/scenarios/a_okvqa/images/Zkx2Q6dT8tpX5CaHAVoLzA.jpg"
              },
              {
                "content_type": "text/plain",
                "text": "What is on the left side of the painting that is on the counter?"
              }
            ]
          }
        },
        "references": [
          {
            "output": {
              "text": "hair"
            },
            "tags": []
          },
          {
            "output": {
              "text": "cat"
            },
            "tags": []
          },
          {
            "output": {
              "text": "dog"
            },
            "tags": []
          },
          {
            "output": {
              "text": "plant"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "valid",
        "id": "id17798"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "A": "hair",
        "B": "cat",
        "C": "dog",
        "D": "plant"
      },
      "request": {
        "model_deployment": "huggingface/qwen2.5-vl-3b-instruct-ft-50",
        "model": "custom/qwen2.5-vl-3b-instruct-ft-50",
        "embedding": false,
        "prompt": "",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 1,
        "stop_sequences": [],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0,
        "multimodal_prompt": {
          "media_objects": [
            {
              "content_type": "text/plain",
              "text": "Answer the multiple choice question by just giving the letter of the correct answer."
            },
            {
              "content_type": "text/plain",
              "text": "\n"
            },
            {
              "content_type": "image/jpeg",
              "location": "benchmark_output/scenarios/a_okvqa/images/Zkx2Q6dT8tpX5CaHAVoLzA.jpg"
            },
            {
              "content_type": "text/plain",
              "text": "What is on the left side of the painting that is on the counter?\nA. hair\nB. cat\nC. dog\nD. plant\nAnswer:"
            }
          ]
        }
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "D",
            "logprob": 0,
            "tokens": [
              {
                "text": "D",
                "logprob": 0
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.7811977863311768,
        "request_datetime": 1764552233
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "",
          "multimedia_content": {
            "media_objects": [
              {
                "content_type": "image/jpeg",
                "location": "benchmark_output/scenarios/a_okvqa/images/Zkx2Q6dT8tpX5CaHAVoLzA.jpg"
              },
              {
                "content_type": "text/plain",
                "text": "What is on da left side of da painting dat is on da counter?"
              }
            ]
          }
        },
        "references": [
          {
            "output": {
              "text": "hair"
            },
            "tags": []
          },
          {
            "output": {
              "text": "cat"
            },
            "tags": []
          },
          {
            "output": {
              "text": "dog"
            },
            "tags": []
          },
          {
            "output": {
              "text": "plant"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "valid",
        "id": "id17798",
        "perturbation": {
          "name": "dialect",
          "robustness": false,
          "fairness": true,
          "computed_on": "perturbed",
          "prob": 1.0,
          "source_class": "SAE",
          "target_class": "AAVE",
          "mapping_file_path": "benchmark_output/perturbations/dialect/SAE_to_AAVE_mapping.json"
        },
        "contrast_inputs": [
          {
            "text": "",
            "multimedia_content": {
              "media_objects": [
                {
                  "content_type": "image/jpeg",
                  "location": "benchmark_output/scenarios/a_okvqa/images/Zkx2Q6dT8tpX5CaHAVoLzA.jpg"
                },
                {
                  "content_type": "text/plain",
                  "text": "What is on the left side of the painting that is on the counter?"
                }
              ]
            }
          }
        ]
      },
      "train_trial_index": 0,
      "output_mapping": {
        "A": "hair",
        "B": "cat",
        "C": "dog",
        "D": "plant"
      },
      "request": {
        "model_deployment": "huggingface/qwen2.5-vl-3b-instruct-ft-50",
        "model": "custom/qwen2.5-vl-3b-instruct-ft-50",
        "embedding": false,
        "prompt": "",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 1,
        "stop_sequences": [],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0,
        "multimodal_prompt": {
          "media_objects": [
            {
              "content_type": "text/plain",
              "text": "Answer the multiple choice question by just giving the letter of the correct answer."
            },
            {
              "content_type": "text/plain",
              "text": "\n"
            },
            {
              "content_type": "image/jpeg",
              "location": "benchmark_output/scenarios/a_okvqa/images/Zkx2Q6dT8tpX5CaHAVoLzA.jpg"
            },
            {
              "content_type": "text/plain",
              "text": "What is on da left side of da painting dat is on da counter?\nA. hair\nB. cat\nC. dog\nD. plant\nAnswer:"
            }
          ]
        }
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "D",
            "logprob": 0,
            "tokens": [
              {
                "text": "D",
                "logprob": 0
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.6823244094848633,
        "request_datetime": 1764552233
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "",
          "multimedia_content": {
            "media_objects": [
              {
                "content_type": "image/jpeg",
                "location": "benchmark_output/scenarios/a_okvqa/images/aJHeEgCPQ2LCEwtsZWbd9Q.jpg"
              },
              {
                "content_type": "text/plain",
                "text": "How can we tell a building is under construction in this area?"
              }
            ]
          }
        },
        "references": [
          {
            "output": {
              "text": "crane"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "video"
            },
            "tags": []
          },
          {
            "output": {
              "text": "dump truck"
            },
            "tags": []
          },
          {
            "output": {
              "text": "signs"
            },
            "tags": []
          }
        ],
        "split": "valid",
        "id": "id17810"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "A": "crane",
        "B": "video",
        "C": "dump truck",
        "D": "signs"
      },
      "request": {
        "model_deployment": "huggingface/qwen2.5-vl-3b-instruct-ft-50",
        "model": "custom/qwen2.5-vl-3b-instruct-ft-50",
        "embedding": false,
        "prompt": "",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 1,
        "stop_sequences": [],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0,
        "multimodal_prompt": {
          "media_objects": [
            {
              "content_type": "text/plain",
              "text": "Answer the multiple choice question by just giving the letter of the correct answer."
            },
            {
              "content_type": "text/plain",
              "text": "\n"
            },
            {
              "content_type": "image/jpeg",
              "location": "benchmark_output/scenarios/a_okvqa/images/aJHeEgCPQ2LCEwtsZWbd9Q.jpg"
            },
            {
              "content_type": "text/plain",
              "text": "How can we tell a building is under construction in this area?\nA. crane\nB. video\nC. dump truck\nD. signs\nAnswer:"
            }
          ]
        }
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "A",
            "logprob": 0,
            "tokens": [
              {
                "text": "A",
                "logprob": 0
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.6087663173675537,
        "request_datetime": 1764552233
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "",
          "multimedia_content": {
            "media_objects": [
              {
                "content_type": "image/jpeg",
                "location": "benchmark_output/scenarios/a_okvqa/images/aJHeEgCPQ2LCEwtsZWbd9Q.jpg"
              },
              {
                "content_type": "text/plain",
                "text": "How can we tell a building is under construction in dis area?"
              }
            ]
          }
        },
        "references": [
          {
            "output": {
              "text": "crane"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "video"
            },
            "tags": []
          },
          {
            "output": {
              "text": "dump truck"
            },
            "tags": []
          },
          {
            "output": {
              "text": "signs"
            },
            "tags": []
          }
        ],
        "split": "valid",
        "id": "id17810",
        "perturbation": {
          "name": "dialect",
          "robustness": false,
          "fairness": true,
          "computed_on": "perturbed",
          "prob": 1.0,
          "source_class": "SAE",
          "target_class": "AAVE",
          "mapping_file_path": "benchmark_output/perturbations/dialect/SAE_to_AAVE_mapping.json"
        },
        "contrast_inputs": [
          {
            "text": "",
            "multimedia_content": {
              "media_objects": [
                {
                  "content_type": "image/jpeg",
                  "location": "benchmark_output/scenarios/a_okvqa/images/aJHeEgCPQ2LCEwtsZWbd9Q.jpg"
                },
                {
                  "content_type": "text/plain",
                  "text": "How can we tell a building is under construction in this area?"
                }
              ]
            }
          }
        ]
      },
      "train_trial_index": 0,
      "output_mapping": {
        "A": "crane",
        "B": "video",
        "C": "dump truck",
        "D": "signs"
      },
      "request": {
        "model_deployment": "huggingface/qwen2.5-vl-3b-instruct-ft-50",
        "model": "custom/qwen2.5-vl-3b-instruct-ft-50",
        "embedding": false,
        "prompt": "",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 1,
        "stop_sequences": [],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0,
        "multimodal_prompt": {
          "media_objects": [
            {
              "content_type": "text/plain",
              "text": "Answer the multiple choice question by just giving the letter of the correct answer."
            },
            {
              "content_type": "text/plain",
              "text": "\n"
            },
            {
              "content_type": "image/jpeg",
              "location": "benchmark_output/scenarios/a_okvqa/images/aJHeEgCPQ2LCEwtsZWbd9Q.jpg"
            },
            {
              "content_type": "text/plain",
              "text": "How can we tell a building is under construction in dis area?\nA. crane\nB. video\nC. dump truck\nD. signs\nAnswer:"
            }
          ]
        }
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "A",
            "logprob": 0,
            "tokens": [
              {
                "text": "A",
                "logprob": 0
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.7128767967224121,
        "request_datetime": 1764552234
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "",
          "multimedia_content": {
            "media_objects": [
              {
                "content_type": "image/jpeg",
                "location": "benchmark_output/scenarios/a_okvqa/images/ZthUeysacKx2CVGPpNKxe4.jpg"
              },
              {
                "content_type": "text/plain",
                "text": "What are the traditional long printed skirts worn by the women called?"
              }
            ]
          }
        },
        "references": [
          {
            "output": {
              "text": "broomstick skirt"
            },
            "tags": []
          },
          {
            "output": {
              "text": "sarong"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "prairie skirt"
            },
            "tags": []
          },
          {
            "output": {
              "text": "accordion skirt"
            },
            "tags": []
          }
        ],
        "split": "valid",
        "id": "id17802"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "A": "broomstick skirt",
        "B": "sarong",
        "C": "prairie skirt",
        "D": "accordion skirt"
      },
      "request": {
        "model_deployment": "huggingface/qwen2.5-vl-3b-instruct-ft-50",
        "model": "custom/qwen2.5-vl-3b-instruct-ft-50",
        "embedding": false,
        "prompt": "",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 1,
        "stop_sequences": [],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0,
        "multimodal_prompt": {
          "media_objects": [
            {
              "content_type": "text/plain",
              "text": "Answer the multiple choice question by just giving the letter of the correct answer."
            },
            {
              "content_type": "text/plain",
              "text": "\n"
            },
            {
              "content_type": "image/jpeg",
              "location": "benchmark_output/scenarios/a_okvqa/images/ZthUeysacKx2CVGPpNKxe4.jpg"
            },
            {
              "content_type": "text/plain",
              "text": "What are the traditional long printed skirts worn by the women called?\nA. broomstick skirt\nB. sarong\nC. prairie skirt\nD. accordion skirt\nAnswer:"
            }
          ]
        }
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "A",
            "logprob": 0,
            "tokens": [
              {
                "text": "A",
                "logprob": 0
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.9989385604858398,
        "request_datetime": 1764552234
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "",
          "multimedia_content": {
            "media_objects": [
              {
                "content_type": "image/jpeg",
                "location": "benchmark_output/scenarios/a_okvqa/images/ZthUeysacKx2CVGPpNKxe4.jpg"
              },
              {
                "content_type": "text/plain",
                "text": "What r the traditional long printed skirts worn by da women called?"
              }
            ]
          }
        },
        "references": [
          {
            "output": {
              "text": "broomstick skirt"
            },
            "tags": []
          },
          {
            "output": {
              "text": "sarong"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "prairie skirt"
            },
            "tags": []
          },
          {
            "output": {
              "text": "accordion skirt"
            },
            "tags": []
          }
        ],
        "split": "valid",
        "id": "id17802",
        "perturbation": {
          "name": "dialect",
          "robustness": false,
          "fairness": true,
          "computed_on": "perturbed",
          "prob": 1.0,
          "source_class": "SAE",
          "target_class": "AAVE",
          "mapping_file_path": "benchmark_output/perturbations/dialect/SAE_to_AAVE_mapping.json"
        },
        "contrast_inputs": [
          {
            "text": "",
            "multimedia_content": {
              "media_objects": [
                {
                  "content_type": "image/jpeg",
                  "location": "benchmark_output/scenarios/a_okvqa/images/ZthUeysacKx2CVGPpNKxe4.jpg"
                },
                {
                  "content_type": "text/plain",
                  "text": "What are the traditional long printed skirts worn by the women called?"
                }
              ]
            }
          }
        ]
      },
      "train_trial_index": 0,
      "output_mapping": {
        "A": "broomstick skirt",
        "B": "sarong",
        "C": "prairie skirt",
        "D": "accordion skirt"
      },
      "request": {
        "model_deployment": "huggingface/qwen2.5-vl-3b-instruct-ft-50",
        "model": "custom/qwen2.5-vl-3b-instruct-ft-50",
        "embedding": false,
        "prompt": "",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 1,
        "stop_sequences": [],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0,
        "multimodal_prompt": {
          "media_objects": [
            {
              "content_type": "text/plain",
              "text": "Answer the multiple choice question by just giving the letter of the correct answer."
            },
            {
              "content_type": "text/plain",
              "text": "\n"
            },
            {
              "content_type": "image/jpeg",
              "location": "benchmark_output/scenarios/a_okvqa/images/ZthUeysacKx2CVGPpNKxe4.jpg"
            },
            {
              "content_type": "text/plain",
              "text": "What r the traditional long printed skirts worn by da women called?\nA. broomstick skirt\nB. sarong\nC. prairie skirt\nD. accordion skirt\nAnswer:"
            }
          ]
        }
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "A",
            "logprob": 0,
            "tokens": [
              {
                "text": "A",
                "logprob": 0
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 1.0035278797149658,
        "request_datetime": 1764552234
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "",
          "multimedia_content": {
            "media_objects": [
              {
                "content_type": "image/jpeg",
                "location": "benchmark_output/scenarios/a_okvqa/images/2oPzCyj5FjrKtBLjGZH2rF.jpg"
              },
              {
                "content_type": "text/plain",
                "text": "What flag is represented on the wall?"
              }
            ]
          }
        },
        "references": [
          {
            "output": {
              "text": "english"
            },
            "tags": []
          },
          {
            "output": {
              "text": "moravian"
            },
            "tags": []
          },
          {
            "output": {
              "text": "american"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "french"
            },
            "tags": []
          }
        ],
        "split": "valid",
        "id": "id17070"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "A": "english",
        "B": "moravian",
        "C": "american",
        "D": "french"
      },
      "request": {
        "model_deployment": "huggingface/qwen2.5-vl-3b-instruct-ft-50",
        "model": "custom/qwen2.5-vl-3b-instruct-ft-50",
        "embedding": false,
        "prompt": "",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 1,
        "stop_sequences": [],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0,
        "multimodal_prompt": {
          "media_objects": [
            {
              "content_type": "text/plain",
              "text": "Answer the multiple choice question by just giving the letter of the correct answer."
            },
            {
              "content_type": "text/plain",
              "text": "\n"
            },
            {
              "content_type": "image/jpeg",
              "location": "benchmark_output/scenarios/a_okvqa/images/2oPzCyj5FjrKtBLjGZH2rF.jpg"
            },
            {
              "content_type": "text/plain",
              "text": "What flag is represented on the wall?\nA. english\nB. moravian\nC. american\nD. french\nAnswer:"
            }
          ]
        }
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "C",
            "logprob": 0,
            "tokens": [
              {
                "text": "C",
                "logprob": 0
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.7141461372375488,
        "request_datetime": 1764552234
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "",
          "multimedia_content": {
            "media_objects": [
              {
                "content_type": "image/jpeg",
                "location": "benchmark_output/scenarios/a_okvqa/images/2oPzCyj5FjrKtBLjGZH2rF.jpg"
              },
              {
                "content_type": "text/plain",
                "text": "What flag is represented on da wall?"
              }
            ]
          }
        },
        "references": [
          {
            "output": {
              "text": "english"
            },
            "tags": []
          },
          {
            "output": {
              "text": "moravian"
            },
            "tags": []
          },
          {
            "output": {
              "text": "american"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "french"
            },
            "tags": []
          }
        ],
        "split": "valid",
        "id": "id17070",
        "perturbation": {
          "name": "dialect",
          "robustness": false,
          "fairness": true,
          "computed_on": "perturbed",
          "prob": 1.0,
          "source_class": "SAE",
          "target_class": "AAVE",
          "mapping_file_path": "benchmark_output/perturbations/dialect/SAE_to_AAVE_mapping.json"
        },
        "contrast_inputs": [
          {
            "text": "",
            "multimedia_content": {
              "media_objects": [
                {
                  "content_type": "image/jpeg",
                  "location": "benchmark_output/scenarios/a_okvqa/images/2oPzCyj5FjrKtBLjGZH2rF.jpg"
                },
                {
                  "content_type": "text/plain",
                  "text": "What flag is represented on the wall?"
                }
              ]
            }
          }
        ]
      },
      "train_trial_index": 0,
      "output_mapping": {
        "A": "english",
        "B": "moravian",
        "C": "american",
        "D": "french"
      },
      "request": {
        "model_deployment": "huggingface/qwen2.5-vl-3b-instruct-ft-50",
        "model": "custom/qwen2.5-vl-3b-instruct-ft-50",
        "embedding": false,
        "prompt": "",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 1,
        "stop_sequences": [],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0,
        "multimodal_prompt": {
          "media_objects": [
            {
              "content_type": "text/plain",
              "text": "Answer the multiple choice question by just giving the letter of the correct answer."
            },
            {
              "content_type": "text/plain",
              "text": "\n"
            },
            {
              "content_type": "image/jpeg",
              "location": "benchmark_output/scenarios/a_okvqa/images/2oPzCyj5FjrKtBLjGZH2rF.jpg"
            },
            {
              "content_type": "text/plain",
              "text": "What flag is represented on da wall?\nA. english\nB. moravian\nC. american\nD. french\nAnswer:"
            }
          ]
        }
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "C",
            "logprob": 0,
            "tokens": [
              {
                "text": "C",
                "logprob": 0
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.8182973861694336,
        "request_datetime": 1764552235
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "",
          "multimedia_content": {
            "media_objects": [
              {
                "content_type": "image/jpeg",
                "location": "benchmark_output/scenarios/a_okvqa/images/2GhdXLaZFBYHSip4rvYKfK.jpg"
              },
              {
                "content_type": "text/plain",
                "text": "The thing on the animal to the left's head is similar to what is on the head of what else?"
              }
            ]
          }
        },
        "references": [
          {
            "output": {
              "text": "devil"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "zombie"
            },
            "tags": []
          },
          {
            "output": {
              "text": "vampire"
            },
            "tags": []
          },
          {
            "output": {
              "text": "witch"
            },
            "tags": []
          }
        ],
        "split": "valid",
        "id": "id17061"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "A": "devil",
        "B": "zombie",
        "C": "vampire",
        "D": "witch"
      },
      "request": {
        "model_deployment": "huggingface/qwen2.5-vl-3b-instruct-ft-50",
        "model": "custom/qwen2.5-vl-3b-instruct-ft-50",
        "embedding": false,
        "prompt": "",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 1,
        "stop_sequences": [],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0,
        "multimodal_prompt": {
          "media_objects": [
            {
              "content_type": "text/plain",
              "text": "Answer the multiple choice question by just giving the letter of the correct answer."
            },
            {
              "content_type": "text/plain",
              "text": "\n"
            },
            {
              "content_type": "image/jpeg",
              "location": "benchmark_output/scenarios/a_okvqa/images/2GhdXLaZFBYHSip4rvYKfK.jpg"
            },
            {
              "content_type": "text/plain",
              "text": "The thing on the animal to the left's head is similar to what is on the head of what else?\nA. devil\nB. zombie\nC. vampire\nD. witch\nAnswer:"
            }
          ]
        }
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "A",
            "logprob": 0,
            "tokens": [
              {
                "text": "A",
                "logprob": 0
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.7288956642150879,
        "request_datetime": 1764552235
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "",
          "multimedia_content": {
            "media_objects": [
              {
                "content_type": "image/jpeg",
                "location": "benchmark_output/scenarios/a_okvqa/images/2GhdXLaZFBYHSip4rvYKfK.jpg"
              },
              {
                "content_type": "text/plain",
                "text": "The thing on da animal to da left's head is similar to wat is on da head of wht else?"
              }
            ]
          }
        },
        "references": [
          {
            "output": {
              "text": "devil"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "zombie"
            },
            "tags": []
          },
          {
            "output": {
              "text": "vampire"
            },
            "tags": []
          },
          {
            "output": {
              "text": "witch"
            },
            "tags": []
          }
        ],
        "split": "valid",
        "id": "id17061",
        "perturbation": {
          "name": "dialect",
          "robustness": false,
          "fairness": true,
          "computed_on": "perturbed",
          "prob": 1.0,
          "source_class": "SAE",
          "target_class": "AAVE",
          "mapping_file_path": "benchmark_output/perturbations/dialect/SAE_to_AAVE_mapping.json"
        },
        "contrast_inputs": [
          {
            "text": "",
            "multimedia_content": {
              "media_objects": [
                {
                  "content_type": "image/jpeg",
                  "location": "benchmark_output/scenarios/a_okvqa/images/2GhdXLaZFBYHSip4rvYKfK.jpg"
                },
                {
                  "content_type": "text/plain",
                  "text": "The thing on the animal to the left's head is similar to what is on the head of what else?"
                }
              ]
            }
          }
        ]
      },
      "train_trial_index": 0,
      "output_mapping": {
        "A": "devil",
        "B": "zombie",
        "C": "vampire",
        "D": "witch"
      },
      "request": {
        "model_deployment": "huggingface/qwen2.5-vl-3b-instruct-ft-50",
        "model": "custom/qwen2.5-vl-3b-instruct-ft-50",
        "embedding": false,
        "prompt": "",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 1,
        "stop_sequences": [],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0,
        "multimodal_prompt": {
          "media_objects": [
            {
              "content_type": "text/plain",
              "text": "Answer the multiple choice question by just giving the letter of the correct answer."
            },
            {
              "content_type": "text/plain",
              "text": "\n"
            },
            {
              "content_type": "image/jpeg",
              "location": "benchmark_output/scenarios/a_okvqa/images/2GhdXLaZFBYHSip4rvYKfK.jpg"
            },
            {
              "content_type": "text/plain",
              "text": "The thing on da animal to da left's head is similar to wat is on da head of wht else?\nA. devil\nB. zombie\nC. vampire\nD. witch\nAnswer:"
            }
          ]
        }
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "A",
            "logprob": 0,
            "tokens": [
              {
                "text": "A",
                "logprob": 0
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.6244950294494629,
        "request_datetime": 1764552235
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "",
          "multimedia_content": {
            "media_objects": [
              {
                "content_type": "image/jpeg",
                "location": "benchmark_output/scenarios/a_okvqa/images/YofsNmbN6XCqNdfHTBmzNq.jpg"
              },
              {
                "content_type": "text/plain",
                "text": "What are the objects made of?"
              }
            ]
          }
        },
        "references": [
          {
            "output": {
              "text": "plastic"
            },
            "tags": []
          },
          {
            "output": {
              "text": "wood"
            },
            "tags": []
          },
          {
            "output": {
              "text": "metal"
            },
            "tags": []
          },
          {
            "output": {
              "text": "acrylic"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "valid",
        "id": "id17774"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "A": "plastic",
        "B": "wood",
        "C": "metal",
        "D": "acrylic"
      },
      "request": {
        "model_deployment": "huggingface/qwen2.5-vl-3b-instruct-ft-50",
        "model": "custom/qwen2.5-vl-3b-instruct-ft-50",
        "embedding": false,
        "prompt": "",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 1,
        "stop_sequences": [],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0,
        "multimodal_prompt": {
          "media_objects": [
            {
              "content_type": "text/plain",
              "text": "Answer the multiple choice question by just giving the letter of the correct answer."
            },
            {
              "content_type": "text/plain",
              "text": "\n"
            },
            {
              "content_type": "image/jpeg",
              "location": "benchmark_output/scenarios/a_okvqa/images/YofsNmbN6XCqNdfHTBmzNq.jpg"
            },
            {
              "content_type": "text/plain",
              "text": "What are the objects made of?\nA. plastic\nB. wood\nC. metal\nD. acrylic\nAnswer:"
            }
          ]
        }
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "D",
            "logprob": 0,
            "tokens": [
              {
                "text": "D",
                "logprob": 0
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.615403413772583,
        "request_datetime": 1764552235
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "",
          "multimedia_content": {
            "media_objects": [
              {
                "content_type": "image/jpeg",
                "location": "benchmark_output/scenarios/a_okvqa/images/YofsNmbN6XCqNdfHTBmzNq.jpg"
              },
              {
                "content_type": "text/plain",
                "text": "What r the objects made of?"
              }
            ]
          }
        },
        "references": [
          {
            "output": {
              "text": "plastic"
            },
            "tags": []
          },
          {
            "output": {
              "text": "wood"
            },
            "tags": []
          },
          {
            "output": {
              "text": "metal"
            },
            "tags": []
          },
          {
            "output": {
              "text": "acrylic"
            },
            "tags": [
              "correct"
            ]
          }
        ],
        "split": "valid",
        "id": "id17774",
        "perturbation": {
          "name": "dialect",
          "robustness": false,
          "fairness": true,
          "computed_on": "perturbed",
          "prob": 1.0,
          "source_class": "SAE",
          "target_class": "AAVE",
          "mapping_file_path": "benchmark_output/perturbations/dialect/SAE_to_AAVE_mapping.json"
        },
        "contrast_inputs": [
          {
            "text": "",
            "multimedia_content": {
              "media_objects": [
                {
                  "content_type": "image/jpeg",
                  "location": "benchmark_output/scenarios/a_okvqa/images/YofsNmbN6XCqNdfHTBmzNq.jpg"
                },
                {
                  "content_type": "text/plain",
                  "text": "What are the objects made of?"
                }
              ]
            }
          }
        ]
      },
      "train_trial_index": 0,
      "output_mapping": {
        "A": "plastic",
        "B": "wood",
        "C": "metal",
        "D": "acrylic"
      },
      "request": {
        "model_deployment": "huggingface/qwen2.5-vl-3b-instruct-ft-50",
        "model": "custom/qwen2.5-vl-3b-instruct-ft-50",
        "embedding": false,
        "prompt": "",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 1,
        "stop_sequences": [],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0,
        "multimodal_prompt": {
          "media_objects": [
            {
              "content_type": "text/plain",
              "text": "Answer the multiple choice question by just giving the letter of the correct answer."
            },
            {
              "content_type": "text/plain",
              "text": "\n"
            },
            {
              "content_type": "image/jpeg",
              "location": "benchmark_output/scenarios/a_okvqa/images/YofsNmbN6XCqNdfHTBmzNq.jpg"
            },
            {
              "content_type": "text/plain",
              "text": "What r the objects made of?\nA. plastic\nB. wood\nC. metal\nD. acrylic\nAnswer:"
            }
          ]
        }
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "D",
            "logprob": 0,
            "tokens": [
              {
                "text": "D",
                "logprob": 0
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.5988171100616455,
        "request_datetime": 1764552236
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "",
          "multimedia_content": {
            "media_objects": [
              {
                "content_type": "image/jpeg",
                "location": "benchmark_output/scenarios/a_okvqa/images/4dnt6ahNTCENKrvBhExyvV.jpg"
              },
              {
                "content_type": "text/plain",
                "text": "Is the man on the left platform going to board the train?"
              }
            ]
          }
        },
        "references": [
          {
            "output": {
              "text": "yes"
            },
            "tags": []
          },
          {
            "output": {
              "text": "absolutely no"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "probably yes"
            },
            "tags": []
          },
          {
            "output": {
              "text": "probably no"
            },
            "tags": []
          }
        ],
        "split": "valid",
        "id": "id17108"
      },
      "train_trial_index": 0,
      "output_mapping": {
        "A": "yes",
        "B": "absolutely no",
        "C": "probably yes",
        "D": "probably no"
      },
      "request": {
        "model_deployment": "huggingface/qwen2.5-vl-3b-instruct-ft-50",
        "model": "custom/qwen2.5-vl-3b-instruct-ft-50",
        "embedding": false,
        "prompt": "",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 1,
        "stop_sequences": [],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0,
        "multimodal_prompt": {
          "media_objects": [
            {
              "content_type": "text/plain",
              "text": "Answer the multiple choice question by just giving the letter of the correct answer."
            },
            {
              "content_type": "text/plain",
              "text": "\n"
            },
            {
              "content_type": "image/jpeg",
              "location": "benchmark_output/scenarios/a_okvqa/images/4dnt6ahNTCENKrvBhExyvV.jpg"
            },
            {
              "content_type": "text/plain",
              "text": "Is the man on the left platform going to board the train?\nA. yes\nB. absolutely no\nC. probably yes\nD. probably no\nAnswer:"
            }
          ]
        }
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "D",
            "logprob": 0,
            "tokens": [
              {
                "text": "D",
                "logprob": 0
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.4530489444732666,
        "request_datetime": 1764552236
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    },
    {
      "instance": {
        "input": {
          "text": "",
          "multimedia_content": {
            "media_objects": [
              {
                "content_type": "image/jpeg",
                "location": "benchmark_output/scenarios/a_okvqa/images/4dnt6ahNTCENKrvBhExyvV.jpg"
              },
              {
                "content_type": "text/plain",
                "text": "Is da man on da left platform goin to board da train?"
              }
            ]
          }
        },
        "references": [
          {
            "output": {
              "text": "yes"
            },
            "tags": []
          },
          {
            "output": {
              "text": "absolutely no"
            },
            "tags": [
              "correct"
            ]
          },
          {
            "output": {
              "text": "probably yes"
            },
            "tags": []
          },
          {
            "output": {
              "text": "probably no"
            },
            "tags": []
          }
        ],
        "split": "valid",
        "id": "id17108",
        "perturbation": {
          "name": "dialect",
          "robustness": false,
          "fairness": true,
          "computed_on": "perturbed",
          "prob": 1.0,
          "source_class": "SAE",
          "target_class": "AAVE",
          "mapping_file_path": "benchmark_output/perturbations/dialect/SAE_to_AAVE_mapping.json"
        },
        "contrast_inputs": [
          {
            "text": "",
            "multimedia_content": {
              "media_objects": [
                {
                  "content_type": "image/jpeg",
                  "location": "benchmark_output/scenarios/a_okvqa/images/4dnt6ahNTCENKrvBhExyvV.jpg"
                },
                {
                  "content_type": "text/plain",
                  "text": "Is the man on the left platform going to board the train?"
                }
              ]
            }
          }
        ]
      },
      "train_trial_index": 0,
      "output_mapping": {
        "A": "yes",
        "B": "absolutely no",
        "C": "probably yes",
        "D": "probably no"
      },
      "request": {
        "model_deployment": "huggingface/qwen2.5-vl-3b-instruct-ft-50",
        "model": "custom/qwen2.5-vl-3b-instruct-ft-50",
        "embedding": false,
        "prompt": "",
        "temperature": 0.0,
        "num_completions": 1,
        "top_k_per_token": 1,
        "max_tokens": 1,
        "stop_sequences": [],
        "echo_prompt": false,
        "top_p": 1,
        "presence_penalty": 0,
        "frequency_penalty": 0,
        "multimodal_prompt": {
          "media_objects": [
            {
              "content_type": "text/plain",
              "text": "Answer the multiple choice question by just giving the letter of the correct answer."
            },
            {
              "content_type": "text/plain",
              "text": "\n"
            },
            {
              "content_type": "image/jpeg",
              "location": "benchmark_output/scenarios/a_okvqa/images/4dnt6ahNTCENKrvBhExyvV.jpg"
            },
            {
              "content_type": "text/plain",
              "text": "Is da man on da left platform goin to board da train?\nA. yes\nB. absolutely no\nC. probably yes\nD. probably no\nAnswer:"
            }
          ]
        }
      },
      "result": {
        "success": true,
        "embedding": [],
        "completions": [
          {
            "text": "D",
            "logprob": 0,
            "tokens": [
              {
                "text": "D",
                "logprob": 0
              }
            ]
          }
        ],
        "cached": false,
        "request_time": 0.5074565410614014,
        "request_datetime": 1764552236
      },
      "num_train_instances": 0,
      "prompt_truncated": false,
      "num_conditioning_tokens": 0
    }
  ]
}